*   **OverThink: Slowdown Attacks on Reasoning LLMs** This paper introduces the OVERTHINK attack, which injects decoy reasoning problems into public content used by reasoning LLMs to force them to "overthink" and increase the number of reasoning tokens used while still providing correct answers. The attack, evaluated on closed and open-weight reasoning models using FreshQA and SQuAD datasets, resulted in slowdowns of up to 18x and 46x respectively, with high transferability across models. The paper also discusses defenses and the societal, financial, and energy impacts of the attack.
*   **Brief analysis of DeepSeek R1 and its implications for Generative AI** This report analyzes DeepSeek's R1 reasoning model, noting its competitive performance relative to OpenAI models despite being developed at a fraction of the cost and under GPU export restrictions. It discusses the innovative use of Mixture of Experts (MoE), Reinforcement Learning (RL), and clever engineering in DeepSeek R1 and other recent Chinese models, and identifies further areas of research.
*   **Can LLMs Maintain Fundamental Abilities under KV Cache Compression?** This paper examines the impact of KV cache compression methods on LLMs' fundamental capabilities across tasks like world knowledge, reasoning, code generation, and safety. The analysis reveals task-specific performance degradation, particularly in arithmetic reasoning, and shows DeepSeek R1 Distill being more robust to compression compared to instruction-tuned models. The authors propose ShotKV, a novel compression approach that improves performance on long-context generation tasks.
*   **ACECODER: Acing Coder RL via Automated Test-Case Synthesis** This paper explores reinforcement learning (RL) for coder models, using automated test-case synthesis to generate training data. A pipeline is designed to create (question, test-cases) pairs from existing code data, enabling the construction of preference pairs and the training of reward models. Experiments show improvements for Llama-3.1-8B-Ins and Qwen2.5-Coder-7B-Ins, with further consistent improvements through RL on various benchmarks.
*   **PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models** This paper presents a benchmark based on the NPR Sunday Puzzle Challenge to test LLMs' reasoning abilities using general knowledge, revealing capability gaps not evident in existing benchmarks. OpenAI o1 outperformed other reasoning models, and analysis of reasoning outputs uncovered new failure modes in DeepSeek R1, such as conceding or not finishing thinking, suggesting the need for inference-time techniques to "wrap up." The paper also quantifies the effectiveness of reasoning longer with R1 and Gemini Thinking.