<?xml version="1.0"?>
<actions>
    <action type="bash" id="install_requests">
        <content>pip install requests</content>
    </action>
    
    <action type="python" id="fetch_craigslist" depends_on="install_requests">
        <content>
import requests
import re
import json

def clean_text(text):
    return re.sub(r'\s+', ' ', text).strip()

def fetch_craigslist_data():
    base_url = "https://portland.craigslist.org/search/clk/syp"
    params = {
        "searchNearby": 1,
        "nearbyArea": "portland",
    }
    
    all_pages_content = []
    page = 0
    last_response = None
    while True:
        try:
            # Add the start index parameter
            params['s'] = page * 120  # Craigslist shows 120 items per page
            
            # Add delay between requests to be respectful
            if page > 0:
                time.sleep(1)
            
            if(page > 5):
                break
            
            print(f"Fetching page {page + 1}...")
            response = requests.get(base_url, params=params, timeout=10)
            if(last_response):
                if response.content == last_response.content:
                    print(f"Duplicate page content detected. Ending search.")
                    break
            
            last_response = response
            
            # Simple check for "no results" text in the response
            if "no results" in response.text.lower() or "nothing found" in response.text.lower():
                print("No more results found.")
                break

            if response.status_code == 200:
                content = response.content
                all_pages_content.append(content)
               
                page += 1
            else:
                print(f"Failed to retrieve page {page + 1}. Status code: {response.status_code}")
                break
                
        except requests.exceptions.RequestException as e:
            print(f"Request error on page {page + 1}: {e}")
            break
        except Exception as e:
            print(f"General error on page {page + 1}: {e}")
            break
    return all_pages_content

print(fetch_craigslist_data())
</content>
    </action>

    <action type="reasoning" id="analyze_listings_1" model="google/gemini-2.0-flash-001" format="json" depends_on="fetch_craigslist">
        <content>
You are a PC hardware expert analyzing Craigslist listings to identify the best deals in Portland, Oregon (specifically Clark County Craigslist).

Here are the Craigslist listings:
{{outputs.fetch_craigslist.raw_response}}

Analyze all provided listings to evaluate which parts represent the best value based on current market prices. Consider the following:

*   **Price vs. Performance:** Prioritize components offering the best performance per dollar based on your expert knowledge of PC hardware.  Consider used prices vs new prices.
    **Highlight the top deals based on the information provided. Provide an estimate of the parts' values if calculating full system estimates.
*   **Avoid hallucinating any further details not provided by the Craigslist information.**

Output a JSON object with a "top_deals" array containing the best deals. For each deal, include the "title", "url", "price", and "reason" as keys. Also include a key containing the number of listings analyzed.
</content>
    </action>

    <action type="reasoning" id="write_markdown_report_1" model="anthropic/claude-3.5-sonnet" depends_on="analyze_listings_1">
        <content>
You are an expert PC hardware reviewer. Based on the following JSON data containing information about craigslist deals, write a markdown report summarizing the best deals for building a gaming PC in Portland, Oregon. Only provide the Markdown document, no surrounding text.

Include an introductory paragraph explaining the methodology used (e.g., analyzing Craigslist listings for price/performance).

For each of the top deals from the "top_deals" array, create a section with:

*   The title of the listing as a header.
*   A link to the Craigslist listing.
*   The price.
*   A detailed explanation of why this is a good deal, referencing specific components and their estimated market value based on expert knowledge.

Conclude with any overall thoughts or warnings about buying used hardware.  Make sure the report is well-organized and easy to read.

Here is the JSON data:
{{outputs.analyze_listings_1.raw_response}}
</content>
    </action>

    <action type="python" id="save_report_1" depends_on="write_markdown_report_1">
        <content>
import datetime

try:
    report = outputs["write_markdown_report_1"]["raw_response"]
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    filename = f"craigslist_pc_deals_{timestamp}.md"

    with open(filename, "w") as f:
        f.write(report)

    print(f"Report saved to {filename}")
except Exception as e:
    print(f"Error saving report: {e}")
</content>
    </action>
</actions>